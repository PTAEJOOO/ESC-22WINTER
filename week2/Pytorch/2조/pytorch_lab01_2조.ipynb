{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjtirCJZF01L",
    "outputId": "d8be5d9a-1125-425d-b3a7-1827c3ecf3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp38-cp38-win_amd64.whl (985 kB)\n",
      "Requirement already satisfied: torch==1.10.1 in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\park sangyung\\anaconda3\\lib\\site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrdnwE-Ckd6z"
   },
   "source": [
    "# Q1 gradient descent로 simple linear regression 추정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV3I2XODkzpq"
   },
   "source": [
    "예제로 사용할 데이터 생성하기\n",
    "\n",
    "$ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\quad \\epsilon_i \\sim  iid N(0, 1)$ \n",
    "\n",
    "$ \\beta_0 = 5, \\beta_1 = 2$라는 모형을 따르는 데이터를 생성해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "DJuJTVrQmFel",
    "outputId": "dd10503e-bd27-41f6-8fce-26154b0c8e07"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_np = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_train_np = 2 *  x_train_np + 5 + norm.rvs(0, 1, size = len(x_train_np)).reshape(-1, 1)\n",
    "\n",
    "plt.scatter(x_train_np, y_train_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdABaEaimr-s"
   },
   "source": [
    "$ \\hat{y_i} = \\beta_0 + \\beta_1 \\times x_i $\n",
    "\n",
    "$ \\hat{y_i} = bias + weight \\times x_i $\n",
    "\n",
    "gradient descent를 사용해 bias와 weight를 학습해보자. \n",
    "\n",
    "1) 추정된 bias와 weight의 결과값은 얼마인가? 그래프를 그려 실제 회귀식에 가깝게 추정되었는지를 확인해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lt6LWxJRmTls"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 1.815, b: 0.295 Cost: 252.754745\n",
      "Epoch  100/1000 W: 2.391, b: 2.150 Cost: 2.911060\n",
      "Epoch  200/1000 W: 2.233, b: 3.200 Cost: 1.749895\n",
      "Epoch  300/1000 W: 2.137, b: 3.839 Cost: 1.320701\n",
      "Epoch  400/1000 W: 2.078, b: 4.228 Cost: 1.162060\n",
      "Epoch  500/1000 W: 2.043, b: 4.464 Cost: 1.103423\n",
      "Epoch  600/1000 W: 2.021, b: 4.607 Cost: 1.081749\n",
      "Epoch  700/1000 W: 2.008, b: 4.695 Cost: 1.073738\n",
      "Epoch  800/1000 W: 2.000, b: 4.748 Cost: 1.070777\n",
      "Epoch  900/1000 W: 1.995, b: 4.780 Cost: 1.069683\n",
      "Epoch 1000/1000 W: 1.992, b: 4.800 Cost: 1.069278\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(x_train_np)\n",
    "y_train = torch.FloatTensor(y_train_np)\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True) # Weight\n",
    "b = torch.zeros(1, requires_grad = True) # bias\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs + 1):\n",
    "\n",
    "  # H(x) 계산\n",
    "  hypothesis = x_train * W + b\n",
    "  \n",
    "  # cost 계산: MSE\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "          epoch, n_epochs, W.item(), b.item(), cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "CLKgfvzhaDu4",
    "outputId": "7c6df380-e78a-4df0-e514-1ed06fbab5f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24439a9d040>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = W * x_train + b # 추정한 회귀식\n",
    "y_real = 2 * x_train + 5 # 실제 회귀식\n",
    "\n",
    "plt.plot(x_train_np, y_pred.detach().numpy())\n",
    "plt.plot(x_train_np, y_real.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNA2S1mmqEvc"
   },
   "source": [
    "2) learning rate를 0.03으로 조정해보자. 어떠한 문제가 발생하는가?\n",
    "\n",
    "답: cost(MSE)가 최소가 되는 점을 찾지 못하고 발산한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4gRKC_F_qcqM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 6.010, b: 0.199 Cost: 340.656281\n",
      "Epoch  100/1000 W: 703.656, b: 109.165 Cost: 15480614.000000\n",
      "Epoch  200/1000 W: 151313.766, b: 22755.871 Cost: 720248635392.000000\n",
      "Epoch  300/1000 W: 32637716.000, b: 4907411.000 Cost: 33510161624596480.000000\n",
      "Epoch  400/1000 W: 7039927296.000, b: 1058524672.000 Cost: 1559098058774648193024.000000\n",
      "Epoch  500/1000 W: 1518503329792.000, b: 228322230272.000 Cost: 72538472985813433446301696.000000\n",
      "Epoch  600/1000 W: 327539272712192.000, b: 49248838090752.000 Cost: 3374924058463756153753046089728.000000\n",
      "Epoch  700/1000 W: 70649811132481536.000, b: 10622911190663168.000 Cost: 157021433680753148051973425380458496.000000\n",
      "Epoch  800/1000 W: 15239097020556771328.000, b: 2291352270593327104.000 Cost: inf\n",
      "Epoch  900/1000 W: 3287052956078018920448.000, b: 494241946790612959232.000 Cost: inf\n",
      "Epoch 1000/1000 W: 709012858264013064110080.000, b: 106607264824075357257728.000 Cost: inf\n"
     ]
    }
   ],
   "source": [
    "# 직접 W와 b를 정의하지 않고, nn.Module을 사용해 손쉽게 선형 모델을 생성할 수 있습니다. \n",
    "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
    "\n",
    "in_features = 1 # your code here\n",
    "out_features = 1 # your code here\n",
    "\n",
    "model = nn.Linear(in_features = in_features, out_features = out_features, bias = True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.03)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W, b, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoLOBBP4tBgc"
   },
   "source": [
    "3) learning rate를 0.00000001로 조정해보자. 어떠한 문제가 발생하는가?\n",
    "\n",
    "답: cost가 최소가 되는 점을 찾기까지 시간이 오래걸린다. epoch수를 늘리면 찾을수도 있지만 비효율적이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5L8OdKyqtNGq",
    "outputId": "532ff27f-e57a-4175-b1e6-5cc9332370bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.000, b: 0.000 Cost: 252.754745\n",
      "Epoch  100/1000 W: 0.000, b: 0.000 Cost: 252.720932\n",
      "Epoch  200/1000 W: 0.000, b: 0.000 Cost: 252.687164\n",
      "Epoch  300/1000 W: 0.001, b: 0.000 Cost: 252.653366\n",
      "Epoch  400/1000 W: 0.001, b: 0.000 Cost: 252.619553\n",
      "Epoch  500/1000 W: 0.001, b: 0.000 Cost: 252.585754\n",
      "Epoch  600/1000 W: 0.001, b: 0.000 Cost: 252.551987\n",
      "Epoch  700/1000 W: 0.001, b: 0.000 Cost: 252.518204\n",
      "Epoch  800/1000 W: 0.001, b: 0.000 Cost: 252.484451\n",
      "Epoch  900/1000 W: 0.002, b: 0.000 Cost: 252.450684\n",
      "Epoch 1000/1000 W: 0.002, b: 0.000 Cost: 252.416916\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad = True) # Weight\n",
    "b = torch.zeros(1, requires_grad = True) # bias\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr = 0.00000001)\n",
    "\n",
    "n_epochs = 1000\n",
    "for epoch in range(n_epochs + 1):\n",
    "\n",
    "  # H(x) 계산\n",
    "  hypothesis = x_train * W + b \n",
    "  \n",
    "  # cost 계산: MSE\n",
    "  cost = torch.mean((hypothesis - y_train)**2)\n",
    "\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwmayIyvdT5W"
   },
   "source": [
    "# Q2. train set and test set - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qckEHyW-t_EQ"
   },
   "source": [
    "MNIST dataset을 불러온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u85modI7dZgP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452b28d844d14f2fa527c57d7d56f4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29ce583908c4b66a04fb3f3f8ebcdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc40ce27cd1c435b87898742d73bae6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea95ac508585429ca14146aa266f2e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "data_loader = DataLoader(dataset = mnist_train,\n",
    "                         batch_size = 100, \n",
    "                         shuffle = True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIuf-1TTuJkB"
   },
   "source": [
    "1) epoch 수를 15로 설정하여 trainset을 훈련시켜보자. \n",
    "\n",
    "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a16aNA_xfH12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.534844875\n",
      "Epoch: 0002 cost = 0.359366417\n",
      "Epoch: 0003 cost = 0.331227601\n",
      "Epoch: 0004 cost = 0.316190422\n",
      "Epoch: 0005 cost = 0.306821167\n",
      "Epoch: 0006 cost = 0.300326347\n",
      "Epoch: 0007 cost = 0.295111746\n",
      "Epoch: 0008 cost = 0.290701479\n",
      "Epoch: 0009 cost = 0.287361264\n",
      "Epoch: 0010 cost = 0.284519643\n",
      "Epoch: 0011 cost = 0.281792253\n",
      "Epoch: 0012 cost = 0.279430926\n",
      "Epoch: 0013 cost = 0.277635366\n",
      "Epoch: 0014 cost = 0.276077867\n",
      "Epoch: 0015 cost = 0.274397463\n"
     ]
    }
   ],
   "source": [
    "# train model with train sets\n",
    "\n",
    "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
    "\n",
    "in_features = 784 # your code here\n",
    "out_features = 10 # your code here\n",
    "linear = torch.nn.Linear(in_features = in_features, out_features=out_features, bias = True)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "training_epochs = 15\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28)\n",
    "        Y = Y\n",
    "\n",
    "        # H(x) 계산\n",
    "        hypothesis = linear(X)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = criterion(hypothesis, Y)\n",
    "\n",
    "        #cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piNVdn75gLKd"
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad(): # torch.no_grad()를 사용하는 이유를 간단하게 설명해봅시다.\n",
    "    # Answer : Testing 시에는, gradient descent를 통해, weight값을 업데이트 하지 않기 때문입니다\n",
    "\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "    print('cost:', cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkFfH5tsuY-G"
   },
   "source": [
    "2) epoch 수를 30으로 설정하여 trainset을 훈련시켜보자. \n",
    "\n",
    "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. \n",
    "\n",
    "어떠한 문제가 발생하는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rcrYS0wVhMlm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.533867478\n",
      "Epoch: 0006 cost = 0.299936056\n",
      "Epoch: 0011 cost = 0.281764925\n",
      "Epoch: 0016 cost = 0.272817284\n",
      "Epoch: 0021 cost = 0.267246068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e97bfc2dd13f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtotal_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linear = torch.nn.Linear(784, 10, bias = True)\n",
    "criterion = torch.nn.CrossEntropyLoss()   \n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "training_epochs = 30\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28)\n",
    "        Y = Y\n",
    "\n",
    "        # H(x) 계산\n",
    "        hypothesis = linear(X)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = criterion(hypothesis, Y)\n",
    "\n",
    "        #cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "      print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g-hNozohXlQ"
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    \n",
    "    print('Accuracy:', accuracy.item())\n",
    "    print('cost:', cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0mGZ5CpmCqK"
   },
   "source": [
    "# Q3. XOR problem with multilayer perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "v2HZ6xpRph0T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8069935441017151\n",
      "50 0.5525302886962891\n",
      "100 0.11521770805120468\n",
      "150 0.042607154697179794\n",
      "200 0.02432074397802353\n",
      "250 0.016639262437820435\n",
      "300 0.01251970324665308\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [0], [1]])\n",
    "\n",
    "# 입출력값의 차원을 고려하여 아래 빈칸을 적절하게 채워주세요\n",
    "linear1 = torch.nn.Linear(2, 2, bias = True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "# 딥러닝의 구조를 고려하여 multi perceptron 모델을 적절하게 생성하세요. \n",
    "# nn.Sequential 함수를 사용하세요\n",
    "model = torch.nn.Sequential(linear1,sigmoid,linear2,sigmoid)\n",
    "\n",
    "# 이 예제에서 cross entropy 대신 BCE를 사용하는 이유를 간단하게 설명하세요\n",
    "# Answer : 다중 분류 문제가 아니라, 이진 분류의 문제이기 때문에 cross entropy 대신 BCE를 사용하게 됩니다.\n",
    "\n",
    "criterion = torch.nn.BCELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "for step in range(301):\n",
    "  hypothesis = model(X)\n",
    "  cost = criterion(hypothesis, Y)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "  if step%50 == 0:\n",
    "    print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXzoKyGxv-aA"
   },
   "source": [
    "## Q4. Sine Function Approximation using the Legendre *Polynomial*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B_VVc1nwJnb"
   },
   "source": [
    "n = 3일때 르장드르 다항식은 다음과 같다. \\\n",
    "$ P_{3} = \\frac{1}{2} (5x^{3} -3x) $ \\\n",
    "이 함수를 사용하여, sine함수를 근사하도록 학습하려고 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE8kJ2AlwJ0B"
   },
   "source": [
    "1) Forward, Backward 함수를 직접 작성하여보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "IxykoRYDwIgA"
   },
   "outputs": [],
   "source": [
    "# 이 클래스에서, forward, backward 함수가 하는 기능이 무엇인지 설명해주세요.\n",
    "# Answer : Forward는 주어진 가중치와 input을 바탕으로 값을 계산하는 과정이고,\n",
    "#          Backward는 gradient를 계산하는 과정이라 할 수 있습니다.\n",
    "\n",
    "class Legendre3Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
    "        # Hint : Legendre Polynomial의 differential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrvjDnuxyGP9"
   },
   "source": [
    "2) 학습을 위한 parameter와 Data를 세팅해보자.\n",
    "   우리가 사용하려는 모델은 다음과 같다.\\\n",
    "   $ y = a + b * P_{3}(c + d * x) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "QeHfE-6tyFSx"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x) # Target function to approximate\n",
    "\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKPsQrW5ywjW"
   },
   "source": [
    "3) 1)에서 정의한 forward, backward 함수를 사용하여,\n",
    "   딥러닝 학습 과정을 직접 작성해보자.\\\n",
    "   \\\n",
    "   Learning rate의 경우, 5e-2, 5e-4, 5e-6, 5e-8 중,\n",
    "   가장 적절한 Learning rate를 찾아보자. \\\n",
    "   적절한 learning rate보다 learning rate가 크거나 작을 때,\n",
    "   어떤 현상이 발생하는지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "bivK3PSHyjyL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.23095129430294037\n",
      "100 0.2254035919904709\n",
      "200 0.2203693687915802\n",
      "300 0.2157878875732422\n",
      "400 0.21160580217838287\n",
      "500 0.20777994394302368\n",
      "600 0.20427197217941284\n",
      "700 0.20104797184467316\n",
      "800 0.19807898998260498\n",
      "900 0.195337176322937\n",
      "1000 0.19280217587947845\n",
      "1100 0.1904541552066803\n",
      "1200 0.18827584385871887\n",
      "1300 0.18625156581401825\n",
      "1400 0.18436777591705322\n",
      "1500 0.18261200189590454\n",
      "1600 0.1809733510017395\n",
      "1700 0.17944201827049255\n",
      "1800 0.17800915241241455\n",
      "1900 0.17666637897491455\n",
      "Result: y = 1.854395630107586e-11 + -1.0020300149917603 * P3(-6.774623223515519e-11 + 0.2771138548851013 x)\n"
     ]
    }
   ],
   "source": [
    "# [5e-2, 5e-4, 5e-6, 5e-8] 중 적절한 learning rate를 찾아주세요.\n",
    "# 적절한 learning rate보다 learning rate가 크거나 작을 때, 어떤 차이가 생기는지\n",
    "# 말씀해주세요.\n",
    "learning_rate = 5e-6\n",
    "\n",
    "# epoch = 2000\n",
    "for t in range(2000):\n",
    "    P3 = Legendre3Function.apply\n",
    "\n",
    "    # Forward pass: predict y.\n",
    "    # P3 using our custom backward function.\n",
    "    y_pred = a + b * P3(c + d * x)\n",
    "\n",
    "    # Compute and print MSE loss\n",
    "    # loss = torch.nn.MSELoss(y_pred, y)\n",
    "    fun = torch.nn.MSELoss()\n",
    "    loss = fun(y_pred, y)\n",
    "    # loss = F.mse_loss(y_pred, y) \n",
    "    \n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM8VpY2Cz0_d"
   },
   "source": [
    "## Q5. Different Basis Function for approximating sine function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC_TprmP1n8J"
   },
   "source": [
    "이번에는 ReLu function을 사용하여 sine함수를 학습해보려 한다. \\\n",
    "ReLu function을 사용했을 때에도, 학습이 잘 되는지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6LOdtF9T0yqi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1.146151065826416\n",
      "199 1.1454650163650513\n",
      "299 1.1447793245315552\n",
      "399 1.1440939903259277\n",
      "499 1.1434091329574585\n",
      "599 1.1427247524261475\n",
      "699 1.1420406103134155\n",
      "799 1.1413570642471313\n",
      "899 1.140674114227295\n",
      "999 1.139991044998169\n",
      "1099 1.1393088102340698\n",
      "1199 1.1386269330978394\n",
      "1299 1.1379454135894775\n",
      "1399 1.1372642517089844\n",
      "1499 1.136583685874939\n",
      "1599 1.1359034776687622\n",
      "1699 1.135223388671875\n",
      "1799 1.134544014930725\n",
      "1899 1.1338649988174438\n",
      "1999 1.1331865787506104\n",
      "Result: y = -0.001565995393320918 + 0.9977350234985352 * ReLu(-0.0009294261690229177 + 0.9977350234985352 x)\n"
     ]
    }
   ],
   "source": [
    "class ReLuFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        # Hint : reLu function의 도함수의 형태를 반영하면 됩니다.\n",
    "        return grad_input\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Our model : y = a + b * ReLu(c + d * x).\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 5e-7\n",
    "for t in range(2000):\n",
    "    ReLu = ReLuFunction.apply\n",
    "\n",
    "    # Forward pass: predict y.\n",
    "    # ReLu using our custom backward function.\n",
    "    y_pred = a + b * ReLu(c + d * x)\n",
    "\n",
    "    # Compute and print MSE loss\n",
    "    fun = torch.nn.MSELoss()\n",
    "    loss = fun(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} * ReLu({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJEtSsDc2gC9"
   },
   "source": [
    "## Q6. \n",
    "Q4, Q5에서 학습한 결과를 바탕으로, 어떤 function을 사용하는 것이 학습에 더 적절했었는지 코멘트해주세요.\n",
    "\n",
    "Answer : 'Relu Function : 1.14 / Legendre function : 0.17'\n",
    "         'Relu Function <<< Legendre function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1bkyVzf3xQI"
   },
   "source": [
    "## Q7. Deep Learning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaLdpBPX4h0e"
   },
   "source": [
    "주어진 데이터를 로딩하고, 아래 코드의 빈칸을 채워\n",
    "딥러닝 학습을 하는 코드를 완성하여보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "B1so2sfQbpd5",
    "outputId": "ba125774-98ea-43b7-8a42-854d6fbb37d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-4c7532dc-f451-4688-b107-10dc4b73fd7f\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-4c7532dc-f451-4688-b107-10dc4b73fd7f\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving testX.csv to testX.csv\n",
      "Saving testY.csv to testY.csv\n",
      "Saving trainX.csv to trainX.csv\n",
      "Saving trainY.csv to trainY.csv\n"
     ]
    }
   ],
   "source": [
    "# 업로드 시간이 7분 30초 가량 걸리기에, 그동안 밑에 코드 작성 먼저 해주셔도 됩니다. (colab 사용시)\n",
    "# colab 사용하시면, 주석 지우고 사용해주세요\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pp21KgUE4x8h"
   },
   "outputs": [],
   "source": [
    "# Data Loading using pd.read_csv\n",
    "\n",
    "train_X = pd.read_csv('trainX.csv')\n",
    "train_Y = pd.read_csv('trainY.csv')\n",
    "\n",
    "test_X = pd.read_csv('testX.csv')\n",
    "test_Y = pd.read_csv('testY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "l0-2JLqg441e"
   },
   "outputs": [],
   "source": [
    "# Data Setting\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)\n",
    "\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)\n",
    "\n",
    "input_dim = len(train_X[0])\n",
    "\n",
    "# Data type casting to torchTensor\n",
    "train_x = torch.FloatTensor(train_X)\n",
    "train_y = torch.FloatTensor(train_Y)\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 4096\n",
    "dataset = TensorDataset(train_x, train_y)\n",
    "\n",
    "# DataLoader setting\n",
    "# 셔플이 있고, batch size에 맞게 dataloader를 세팅해주세요,\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "LV6Sgdv15nkM"
   },
   "outputs": [],
   "source": [
    "# Model Setting\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, int(input_dim/6)),\n",
    "    # 각 Layer의 activation function을 설정해주세요.\n",
    "    torch.nn.ReLU(),\n",
    "    # Hint : hidden layer activation function ReLu\n",
    "    torch.nn.Linear(int(input_dim/6), int(input_dim/5)),\n",
    "    torch.nn.ReLU(),\n",
    "    # Hint : hidden layer activation function ReLu\n",
    "    torch.nn.Linear(int(input_dim/5), 1),\n",
    "    torch.nn.Sigmoid(),\n",
    "    # Hint : Output layer activation function for binary classification\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LLXeKJC6rIi",
    "outputId": "dd4ddeb2-3181-46d8-d467-37e503413449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 1977 elements\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print(\"The number of parameters:\", sum([p.numel() for p in model.parameters() if p.requires_grad]), \"elements\")\n",
    "x = torch.from_numpy(train_X.astype(np.float32))\n",
    "y = torch.from_numpy(train_Y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# loss function 부분을 채워주세요.\n",
    "# BCE loss를 사용합니다.\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "xyGnAGQJ6Ihy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0/200 loss: 0.7010\n",
      "iter 10/200 loss: 0.5391\n",
      "iter 20/200 loss: 0.5230\n",
      "iter 30/200 loss: 0.5112\n",
      "iter 40/200 loss: 0.5032\n",
      "iter 50/200 loss: 0.4853\n",
      "iter 60/200 loss: 0.4907\n",
      "iter 70/200 loss: 0.4896\n",
      "iter 80/200 loss: 0.4917\n",
      "iter 90/200 loss: 0.4827\n",
      "iter 100/200 loss: 0.4791\n",
      "iter 110/200 loss: 0.4870\n",
      "iter 120/200 loss: 0.4753\n",
      "iter 130/200 loss: 0.4804\n",
      "iter 140/200 loss: 0.4811\n",
      "iter 150/200 loss: 0.4855\n",
      "iter 160/200 loss: 0.4800\n",
      "iter 170/200 loss: 0.4903\n",
      "iter 180/200 loss: 0.4851\n",
      "iter 190/200 loss: 0.4772\n",
      "iter 200/200 loss: 0.4888\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "iter = 200\n",
    "loss_list = []\n",
    "# Adam optimizer를 설정해주세요. learning rate, 그리고 weight_decay는 5e-2로 설정해주세요.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-2, weight_decay = 5e-2)\n",
    "\n",
    "prev_loss = 1e+30\n",
    "\n",
    "for t in range(iter+1):\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "      trainx, trainy = sample\n",
    "      y_pred = model(trainx)\n",
    "\n",
    "      loss = loss_fn(y_pred, trainy)\n",
    "\n",
    "      # gradient 계산 및 gradient descent 계산을 통한 optimization 부분\n",
    "      # 코드를 채워주세요.\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    \n",
    "      loss_list.append(loss.item())\n",
    "\n",
    "    cur_loss = np.mean(loss_list[max(0, len(loss_list)-batch-1):len(loss_list)-1])\n",
    "    \n",
    "    if t % 10 == 0:\n",
    "      print('iter {}/{} loss: {:.4f}'.format(\n",
    "             t, iter, cur_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "uYrvNZ-68Y_L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1: 0.8185395650730694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2443995e160>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict = model(torch.from_numpy(test_X.astype(np.float32)))\n",
    "y_pred = y_predict.detach().numpy()\n",
    "\n",
    "# test set의 prediction값을 계산하는 식을 작성하고, weighted f1 score를 계산해주세요.\n",
    "y_pred = [1 if t > 0.5 else 0 for t in y_pred]\n",
    "result = f1_score(y_pred, test_Y, average=\"weighted\")\n",
    "\n",
    "# 결과물 출력\n",
    "print(\"Weighted F1:\", result)\n",
    "step = np.linspace(0, len(loss_list), len(loss_list))\n",
    "plt.plot(step/int(batch_size + 1), np.array(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jXzoKyGxv-aA",
    "DM8VpY2Cz0_d"
   ],
   "name": "pytorch_lab01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
